{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "771cf430",
   "metadata": {},
   "source": [
    "## **CS:345 Multilingual Emotion Detection in Social Media**\n",
    "\n",
    "### **Team Members**\n",
    "1. Abeeb Abdullahi Samuel\n",
    "2. Maereg Habtezgi \n",
    "\n",
    "### **Introduction**\n",
    "\n",
    "Social media platforms like Twitter generate vast volumes of short texts that convey a wide spectrum of emotions. This project aims to build an automated system for emotion detection in these posts by fine-tuning transformer-based language modelsâ€”such as BERT-base-multilingual-cased and XLM-RoBERTa-baseâ€”on two Twitter-sourced datasets. We will evaluate which modelâ€“dataset combination best captures the subtle nuances of emotional expression, addresses challenges like data imbalance and linguistic variability, and can serve as the foundation for future emotion-classification tasks.\n",
    "\n",
    "- **BERT (Bidirectional Encoder Representations from Transformers)**\n",
    "- **XLM-RoBERTa (Cross-lingual Language Model)**\n",
    "\n",
    "The datasets used for training and evaluation are:\n",
    "\n",
    "- [`TweetEval`](https://huggingface.co/datasets/cardiffnlp/tweet_eval): A benchmark suite of tasks built on English tweets.\n",
    "- [`SuperTweetEval`](https://huggingface.co/datasets/cardiffnlp/super_tweeteval): An extended multilingual version supporting more complex evaluation, including multi-label emotion classification.\n",
    "\n",
    "\n",
    "> **Note:** We have excluded the SEMEVAL-11 dataset from our experiments and are using only the two current Twitter-sourced datasets for the following reasons:\n",
    "> 1. **Richer annotations:** The two chosen datasets provide more granular emotion categories, clearer label definitions, and additional metadata columns compared to SEMEVAL-11.  \n",
    "> 2. **Availability:** SEMEVAL-11 is no longer hosted on the Hugging Face platform and cannot be accessed for fine-tuning.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Our aim is to adapt these models to accurately classify a range of emotions datasest found in tweets, evaluating their strengths and challenges during fine-tuning. And see which model perfroms best with which result.\n",
    "\n",
    "---\n",
    "\n",
    "### **Project Structure**\n",
    "\n",
    "This project is divided into **three Jupyter notebooks** for clarity and modular experimentation:\n",
    "\n",
    "#### 1. `BERT_Finetune.ipynb`\n",
    "\n",
    "This notebook focuses on:\n",
    "\n",
    "- Fine-tuning the BERT-based model (including `bert-base-uncased`, `twitter-roberta-base` and its variants) on both TweetEval and SuperTweetEval .\n",
    "- Preprocessing steps like emoji normalization and tokenization tailored for social media content.\n",
    "- Handling class imbalance and improving performance through parameter tuning.\n",
    "- Tracking training/validation metrics and analyzing results across epochs.\n",
    "\n",
    "#### 2. `XLM_Finetune.ipynb`\n",
    "\n",
    "This notebook covers:\n",
    "\n",
    "- Fine-tuning the multilingual `XLM-RoBERTa` (and its variants) model on both TweetEval and SuperTweetEval.\n",
    "- Addressing challenges in cross-lingual emotion classification.\n",
    "- Analyzing model performance on non-English tweets.\n",
    "- Comparative metrics and evaluation of zero-shot or low-resource performance.\n",
    "\n",
    "#### 3. `Conclusion.ipynb`\n",
    "\n",
    "This notebook provides:\n",
    "\n",
    "- A summary of findings from both BERT and XLM fine-tuning experiments.\n",
    "- A comparative analysis of accuracy and F1 performance across both datasets.\n",
    "- Key challenges, trade-offs, and recommendations for future work (e.g., better handling of multi-label classification, cross-lingual transfer learning, or low-resource language support)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e568a3a",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### **Section 1: Finetuning XLM with TweetEval**\n",
    "\n",
    "In this section, we fine-tune a XLM-based model on the **`TweetEval`** dataset, specifically the **emotion classification** task. This dataset comprises short texts (tweets) labeled with a single emotion class, making it a **single-label classification problem**.\n",
    "\n",
    "#### Dataset Overview\n",
    "\n",
    "The **TweetEval: Emotion** configuration contains tweets annotated with one of **four emotion categories**, each mapped to an integer label:\n",
    "\n",
    "| Label | Emotion   |\n",
    "|-------|-----------|\n",
    "| 0     | Anger     |\n",
    "| 1     | Joy       |\n",
    "| 2     | Optimism  |\n",
    "| 3     | Sadness   |\n",
    "\n",
    "Each training example consists of:\n",
    "- `text` â€” the tweet in plain text.\n",
    "- `label` â€” an integer representing the emotion class.\n",
    "\n",
    "**Example entry:**\n",
    "```json\n",
    "{\n",
    "  \"text\": \"Feeling amazing after that workout\",\n",
    "  \"label\": 1  // Joy\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e259f3d",
   "metadata": {},
   "source": [
    "### **Environment Setup and Data Loading**\n",
    "\n",
    "We first start by configuring the environment for CPU-based computations by letting it sets the number of threads for OpenMP and OpenBLAS to 4, and also instructs PyTorch to utilize a maximum of 4 CPU threads. Following the environment setup, we loaded loads the \"emotion\" split of the \"tweet_eval\" dataset directly from the Hugging Face Datasets library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89e771a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n",
    "                          TrainingArguments, Trainer)\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"4\"\n",
    "torch.set_num_threads(4)\n",
    "\n",
    "dataset = load_dataset(\"cardiffnlp/tweet_eval\", \"emotion\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad5f1cc",
   "metadata": {},
   "source": [
    "### **Model Selection and initialization**\n",
    "\n",
    "We initially aimed to use the **`xlm-roberta-large`** model. However, we encountered the following error: 'The kernel '**`CS345Project-env (Python 3.13.3)' died. ExitCode: 3221225477`**'. This resulted in kernel crashes, which we was due to Out Of Memory (OOM) issue due to the model's large size exceeding our training machine's memory capacity. So, we switched for the **`xlm-roberta-base model`**, which is a powerful yet significantly lighter alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d067b015",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 374/374 [00:00<00:00, 7992.28 examples/s]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"xlm-roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=4)\n",
    "\n",
    "def preprocess_fn(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "tokenized_datasets = dataset.map(preprocess_fn, batched=True, remove_columns=[\"text\"])\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "train_dataset = tokenized_datasets[\"train\"]\n",
    "eval_dataset  = tokenized_datasets[\"validation\"]\n",
    "test_dataset  = tokenized_datasets[\"test\"]\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='macro')\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a903d34b",
   "metadata": {},
   "source": [
    "### **Training Setup and Argumenets** \n",
    "We fine-tuned the model intially starting with configurations, We set the:\n",
    "\n",
    "* **Epochs** to **5** to allows the model to learn from the data multiple times. We saw that in the second training of BERT that 3 epochs gave decent performance, and 5 epochs showed a slight increase in validation F1, so it's a reasonable choice to explore.\n",
    "\n",
    "* **Learning Rate** to **2e-5** because 2e-5 it's generally a good starting point that's not too aggressive (which could lead to instability) and not too slow (which could lead to very long training times). and because we also saw an inprovement from our second training of BERT whe we switched from 1e-5 to 2e-5.  \n",
    "\n",
    "* **weight_decay** to **0.01** to helps prevent overfitting by adding a penalty to large weight values and 0.01 is a standard value for weight decay for this.\n",
    "\n",
    "* **gradient_accumulation_steps** to **2** because With `per_device_train_batch_size=8` and `gradient_accumulation_steps=2`, the model will accumulate gradients over 2 forward/backward passes before performing an optimization step. This effectively simulates a batch size of $8 \\times 2 = 16$, which can lead to more stable training than a very small actual batch size on CPU.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da9ab4d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samabdul\\Desktop\\CS345Project\\CS345Project\\CS345Project-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1421/1421 [00:00<00:00, 11366.27 examples/s]\n",
      "c:\\Users\\samabdul\\Desktop\\CS345Project\\CS345Project\\CS345Project-env\\Lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "c:\\Users\\samabdul\\Desktop\\CS345Project\\CS345Project\\CS345Project-env\\Lib\\site-packages\\transformers\\training_args.py:1609: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of ðŸ¤— Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1020' max='1020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1020/1020 2:04:59, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.848100</td>\n",
       "      <td>0.797157</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.581900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.545700</td>\n",
       "      <td>0.797824</td>\n",
       "      <td>0.732620</td>\n",
       "      <td>0.661805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.469200</td>\n",
       "      <td>0.768861</td>\n",
       "      <td>0.751337</td>\n",
       "      <td>0.672779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.409700</td>\n",
       "      <td>0.870386</td>\n",
       "      <td>0.743316</td>\n",
       "      <td>0.671127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.258600</td>\n",
       "      <td>0.830032</td>\n",
       "      <td>0.767380</td>\n",
       "      <td>0.701716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='178' max='178' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [178/178 01:52]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (base): 0.8086 \t Test F1 (base): 0.7822\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_base\", \n",
    "    num_train_epochs=5,\n",
    "    per_device_train_batch_size=8,  \n",
    "    per_device_eval_batch_size=8,\n",
    "    gradient_accumulation_steps=2, \n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    no_cuda=True,\n",
    "    logging_steps=10,\n",
    "    logging_dir=\"./logs_base\",     \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "test_results = trainer.evaluate(eval_dataset=test_dataset)\n",
    "print(\"Test Accuracy (base): {:.4f} \\t Test F1 (base): {:.4f}\".format(test_results[\"eval_accuracy\"], test_results[\"eval_f1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480c1d27",
   "metadata": {},
   "source": [
    "### **Training Arguments and Hyperparameter Tuning**\n",
    "\n",
    "After the initial training phase, the model achieved:\n",
    "\n",
    "* **Test Accuracy**: `0.8086`\n",
    "* **Test F1 Score**: `0.7822`\n",
    "\n",
    "These results were promising, suggesting the model was learning meaningful patterns. To further explore potential improvements, we made the following changes:\n",
    "\n",
    "* **Increased training epochs**: from `5` to `8`\n",
    "* **Reduced learning rate**: from `2e-5` to `1e-5`\n",
    "* **Increased batch size**: from `8` to `16` (while adjusting `gradient_accumulation_steps` from `2` to `1` to maintain a similar effective batch size)\n",
    "* **Updated output and logging directories** for clearer organization\n",
    "\n",
    "A smaller learning rate was chosen to allow for finer-grained updates to model weights, especially in later epochs, where overfitting or overshooting can occur more easily.\n",
    "\n",
    "We resumed training from the checkpoint at:\n",
    "\n",
    "```\n",
    "./results_base/checkpoint-612\n",
    "```\n",
    "\n",
    "This checkpoint was selected as it corresponded to a well-performing state during the earlier training phase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7960d5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: The following arguments do not match the ones in the `trainer_state.json` within the checkpoint directory: \n",
      "\tper_device_train_batch_size: 16 (from args) != 8 (from trainer_state.json)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3264' max='3264' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3264/3264 3:37:57, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.434900</td>\n",
       "      <td>1.142483</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.676292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.486200</td>\n",
       "      <td>1.151979</td>\n",
       "      <td>0.743316</td>\n",
       "      <td>0.676838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.086300</td>\n",
       "      <td>1.385637</td>\n",
       "      <td>0.732620</td>\n",
       "      <td>0.656986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.230700</td>\n",
       "      <td>1.337235</td>\n",
       "      <td>0.775401</td>\n",
       "      <td>0.717035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.483800</td>\n",
       "      <td>1.436211</td>\n",
       "      <td>0.762032</td>\n",
       "      <td>0.696618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>1.520651</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.718210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.056800</td>\n",
       "      <td>1.548698</td>\n",
       "      <td>0.770053</td>\n",
       "      <td>0.712422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='89' max='89' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [89/89 02:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy (tuned): 0.7987 \t Test F1 (tuned): 0.7683\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "training_args_tuned = TrainingArguments(\n",
    "    output_dir=\"./results_tuned\",  \n",
    "    num_train_epochs=8,             \n",
    "    per_device_train_batch_size=16,  \n",
    "    per_device_eval_batch_size=16,\n",
    "    gradient_accumulation_steps=1,  \n",
    "    learning_rate=1e-5,            \n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    no_cuda=True,\n",
    "    logging_steps=10,\n",
    "    logging_dir=\"./logs_tuned\",     \n",
    ")\n",
    "\n",
    "trainer_tuned = Trainer(\n",
    "    model=model,                     \n",
    "    args=training_args_tuned,\n",
    "    train_dataset=train_dataset,     \n",
    "    eval_dataset=eval_dataset,       \n",
    "    compute_metrics=compute_metrics,  \n",
    ")\n",
    "\n",
    "trainer_tuned.train(resume_from_checkpoint=\"./results_base/checkpoint-612\")\n",
    "\n",
    "test_results_tuned = trainer_tuned.evaluate(eval_dataset=test_dataset)\n",
    "print(\"Test Accuracy (tuned): {:.4f} \\t Test F1 (tuned): {:.4f}\".format(test_results_tuned[\"eval_accuracy\"], test_results_tuned[\"eval_f1\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6e8a8f",
   "metadata": {},
   "source": [
    "### **Conclusion for XLM and TweetEval Training**\n",
    "\n",
    "We began by fine-tuning the model for 5 epochs and achieved:\n",
    "\n",
    "* **Test Accuracy**: 0.8086\n",
    "* **Test F1 Score**: 0.7822\n",
    "\n",
    "Despite further hyperparameter tuning (increasing epochs, adjusting learning rate, batch size, and gradient accumulation steps), performance showed signs of overfitting after 8 epochs. Specifically, the validation loss began to rise, and accuracy and F1 scores plateaued or decreased. After training for 8 epochs, the results were:\n",
    "\n",
    "* **Test Accuracy**: 0.7701\n",
    "* **Test F1 Score**: 0.7124\n",
    "\n",
    "To avoid overfitting and maintain a model that generalizes well, we decided to proceed with the initial 5-epoch model. This decision was based on the solid performance and better generalization observed during the earlier phase.\n",
    "\n",
    "### **Next Steps**\n",
    "\n",
    "* **Model Deployment**: We will save and deploy the first model trained for 5 epochs, as it offers the best balance of performance and generalization.\n",
    "\n",
    "In conclusion, while we made several adjustments during training, the initial 5-epoch model provides the most reliable results. Fine-tuning further with a lower learning rate seemed to reduce accuracy and hinder the model's performance, making the 5-epoch model the best choice for deployment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f75e4b7",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "###  **Section 2: Finetuning BERT with SuperTweetEval**\n",
    "\n",
    "In this section, we fine-tune a BERT-based model on the **`SuperTweetEval`** dataset, specifically the **emotion classification** task. This dataset comprises short texts (tweets) labeled with one or more emotions, making it a **multi-label classification problem**.\n",
    "\n",
    "#### **Dataset Overview**\n",
    "\n",
    "The **SuperTweetEval: TweetEmotion** configuration contains tweets annotated with one or more of the following **11 emotion categories**:\n",
    "\n",
    "| Label | Emotion      |\n",
    "| ----- | ------------ |\n",
    "| 0     | Anger        |\n",
    "| 1     | Anticipation |\n",
    "| 2     | Disgust      |\n",
    "| 3     | Fear         |\n",
    "| 4     | Joy          |\n",
    "| 5     | Love         |\n",
    "| 6     | Optimism     |\n",
    "| 7     | Pessimism    |\n",
    "| 8     | Sadness      |\n",
    "| 9     | Surprise     |\n",
    "| 10    | Trust        |\n",
    "\n",
    "Each training example consists of:\n",
    "\n",
    "* `text` â€” the tweet in plain text.\n",
    "* `'gold_label_list` â€” a list of binary values or class indices representing the presence of each emotion.\n",
    "\n",
    "**Example entry:**\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"text\": \"Feeling amazing after that workout\",\n",
    "  \"labels\": [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0]  // Joy and Optimism\n",
    "}\n",
    "```\n",
    "\n",
    "----\n",
    "We start by importing the necessary dependcies and  loaded the dataset and inspect the emotion label mapping. We loaded and printed the data using the following code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7eda6a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"â€œWorry is a down payment on a problem you may never have'. Joyce Meyer. #motivation #leadership #worry\", 'gold_label_list': [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1]}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"cardiffnlp/super_tweeteval\", \"tweet_emotion\")\n",
    "print(dataset['train'][0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb8526b",
   "metadata": {},
   "source": [
    "### **Model Setup and Preprocessing**\n",
    "We continue to use the **`xlm-roberta-base`** model and tokenizer as a better alternative to **`xlm-roberta-large`**, which has shown very promising results in our initial fine-tuning on TweetEval (single-label classification) with the following.\n",
    "\n",
    "  \n",
    " - **Model & Tokenization**: We loaded a sequence-classification head on top of XLM-RoBERTa, configured for 4 output labels. We also converted each exampleâ€™s `\"text\"` field into `input_ids` and `attention_mask`, truncating to the modelâ€™s maximum length.  \n",
    "\n",
    "- **Metric Computation** We compute Accuracy â€” the fraction of correctly classified examples â€” and Weighted F1 Score â€” the harmonic mean of precision and recall, weighted by class support to account for label imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d79fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"xlm-roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=4) # 4 labels: anger, joy, optimism, sadness\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "tokenized_datasets = dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "def preprocess_function_with_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"text\"], truncation=True)\n",
    "    labels = []\n",
    "    for label_list in examples[\"gold_label_list\"]:\n",
    "        if isinstance(label_list, list) and len(label_list) > 0:\n",
    "            labels.append(label_list[0])\n",
    "        elif isinstance(label_list, int):\n",
    "            labels.append(label_list)\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected label format: {label_list}\")\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.map(preprocess_function_with_labels, batched=True)\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d717c6c",
   "metadata": {},
   "source": [
    "### **Training Arguments and Set up**\n",
    "We continue to use consistent training arguments, as they tend to produce better and more stable results. We configured the **training parameters** and **Trainer** for fine-tuning the **XLM-RoBERTa-base** model for the following reasons:\n",
    "\n",
    "1. **Training Arguments**: We set up the **`TrainingArguments`** to specify key training behaviors based on the task and dataset size:\n",
    "\n",
    "   - **Learning Rate (2e-5)**: A standard learning rate for transformer fine-tuning, balancing convergence speed and stability.\n",
    "\n",
    "   - **Epochs (5)**: Five passes over the training data provide enough exposure for convergence without overfitting on the relatively small dataset.\n",
    "\n",
    "   - **Weight Decay (0.01)**: Applied for regularization to prevent overfitting, which is especially helpful on smaller datasets.\n",
    "\n",
    "   - **Evaluation & Saving (`epoch`)**: Both evaluation and model checkpoint saving occur at the end of each epoch to monitor progress and preserve milestones.\n",
    "\n",
    "   - These values are selected to support consistent, stable fine-tuning on the emotion classification task while tracking and saving the best-performing model.\n",
    "\n",
    "2. **Trainer Initialization**: The **`Trainer`** is instantiated with the model, training arguments, tokenized datasets (train/validation), tokenizer, and the custom `compute_metrics` function to automate training and evaluation.\n",
    "\n",
    "3. **Model Training**: The training is started via `trainer.train()`, which handles all optimization, evaluation, and checkpointing automatically based on the defined settings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2db231b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samabdul\\Desktop\\CS345Project\\CS345Project\\CS345Project-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': \"â€œWorry is a down payment on a problem you may never have'. Joyce Meyer. #motivation #leadership #worry\", 'gold_label_list': [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\samabdul\\Desktop\\CS345Project\\CS345Project\\CS345Project-env\\Lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\samabdul\\AppData\\Local\\Temp\\ipykernel_12524\\325717812.py:61: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2140' max='2140' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2140/2140 2:19:14, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.440534</td>\n",
       "      <td>0.812641</td>\n",
       "      <td>0.811647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.525400</td>\n",
       "      <td>0.494009</td>\n",
       "      <td>0.812641</td>\n",
       "      <td>0.815163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.332600</td>\n",
       "      <td>0.520686</td>\n",
       "      <td>0.822799</td>\n",
       "      <td>0.823107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.251200</td>\n",
       "      <td>0.676817</td>\n",
       "      <td>0.814898</td>\n",
       "      <td>0.813138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.181700</td>\n",
       "      <td>0.738630</td>\n",
       "      <td>0.819413</td>\n",
       "      <td>0.819151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2140, training_loss=0.3130605965017158, metrics={'train_runtime': 8359.4146, 'train_samples_per_second': 4.09, 'train_steps_per_second': 0.256, 'total_flos': 821915112646992.0, 'train_loss': 0.3130605965017158, 'epoch': 5.0})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./xlm-roberta-tweet-emotion\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    push_to_hub=False, \n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15603ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions: (3259, 4)\n",
      "Test Accuracy: 0.8272476219699294\n",
      "Test F1 Score: 0.8305641364042509\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_results = trainer.predict(tokenized_datasets[\"test\"])\n",
    "print(f\"Test predictions: {test_results.predictions.shape}\")\n",
    "\n",
    "predicted_labels = np.argmax(test_results.predictions, axis=-1)\n",
    "true_labels = tokenized_datasets[\"test\"][\"labels\"]\n",
    "\n",
    "test_accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "test_f1 = f1_score(true_labels, predicted_labels, average=\"weighted\")\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test F1 Score: {test_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4074fce0",
   "metadata": {},
   "source": [
    "### **Model Evaluation & Error Analysis**\n",
    "\n",
    "After the first training, the model performed well, achieving an **accuracy of 0.827** and an **F1 score of 0.83**, which is a strong result for an initial run. To identify potential areas for improvement, we conducted an in-depth evaluation of the dataset and model predictions. Here's what we discovered:\n",
    "\n",
    "* **Class Imbalance** We observed that the dataset is imbalanced, with significantly more **Anger** examples than **Anticipation**, which likely biased the model during training.\n",
    "\n",
    "  * **Evidence:**\n",
    "\n",
    "    * **Training set:** Anger â€“ 4,294 | Anticipation â€“ 2,544\n",
    "    * **Validation set:** Anger â€“ 571 | Anticipation â€“ 315\n",
    "    * **Test set:** Anger â€“ 2,158 | Anticipation â€“ 1,101\n",
    "      This imbalance contributed to the model overpredicting **Anger** in several cases.\n",
    "\n",
    "\n",
    "* **Confusion Matrix Analysis** The confusion matrix alsoe showed that the model still occasionally misclassifies **Anticipation** tweets as **Anger**, although the **recall for Anticipation improved** after applying class weighting.\n",
    "\n",
    "  * **Evidence:**\n",
    "\n",
    "    * **True Anticipation â†’ Predicted Anger:** 166 instances\n",
    "    * **True Anger â†’ Predicted Anticipation:** 397 instances\n",
    "    * **Anticipation recall** increased to **0.8492**, indicating improved sensitivity to the minority class compared to earlier (unweighted) runs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "60d7a622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train distribution: Counter({0: 4294, 1: 2544})\n",
      "Val   distribution: Counter({0: 571, 1: 315})\n",
      "Test  distribution: Counter({np.int64(0): 2158, np.int64(1): 1101})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count true labels in train/val/test\n",
    "print(\"Train distribution:\", Counter(tokenized_datasets[\"train\"][\"labels\"]))\n",
    "print(\"Val   distribution:\", Counter(tokenized_datasets[\"validation\"][\"labels\"]))\n",
    "print(\"Test  distribution:\", Counter(true_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa8b8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_output = trainer.predict(tokenized_datasets[\"test\"])\n",
    "\n",
    "logits = predictions_output.predictions \n",
    "true_labels = predictions_output.label_ids\n",
    "preds = np.argmax(logits, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "35307c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels present in this split: [0, 1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Anger     0.9139    0.8160    0.8622      2158\n",
      "Anticipation     0.7020    0.8492    0.7686      1101\n",
      "\n",
      "    accuracy                         0.8272      3259\n",
      "   macro avg     0.8079    0.8326    0.8154      3259\n",
      "weighted avg     0.8423    0.8272    0.8306      3259\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "all_label_names = [\n",
    "    \"Anger\",\"Anticipation\",\"Disgust\",\"Fear\",\"Joy\",\n",
    "    \"Love\",\"Optimism\",\"Pessimism\",\"Sadness\",\"Surprise\",\"Trust\"\n",
    "]\n",
    "\n",
    "unique_labels = np.unique(true_labels).tolist()\n",
    "print(\"Labels present in this split:\", unique_labels)\n",
    "\n",
    "present_names = [all_label_names[i] for i in unique_labels]\n",
    "\n",
    "cm = confusion_matrix(true_labels, preds, labels=unique_labels)\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\",\n",
    "            xticklabels=present_names,\n",
    "            yticklabels=present_names,\n",
    "            cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix (present classes only)\")\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(\n",
    "    true_labels, preds,\n",
    "    labels=unique_labels,\n",
    "    target_names=present_names,\n",
    "    digits=4\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0aacfd2",
   "metadata": {},
   "source": [
    "### **Next Steps & Improvements**\n",
    "\n",
    "Based on the issues revealed particularly the **class imbalance** and systematic **misclassification of Anticipation as Anger** we:\n",
    "\n",
    " **Introduced Class-Weighted Loss** becuase the confusion matrix and classification report showed clear underperformance on the minority class (**Anticipation**), likely due to dominance by the majority class (**Anger**). So we applied a **class-weighted loss function**  which penalizes errors on minority classes more heavily during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bca850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch\n",
    "\n",
    "train_labels = np.array(tokenized_datasets[\"train\"][\"labels\"])\n",
    "\n",
    "weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(train_labels),\n",
    "    y=train_labels\n",
    ")\n",
    "class_weights = torch.tensor([1.5, 5.0, 1.0, 1.0]).to(model.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1fc2bb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\samabdul\\Desktop\\CS345Project\\CS345Project\\CS345Project-env\\Lib\\site-packages\\transformers\\training_args.py:1594: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\samabdul\\AppData\\Local\\Temp\\ipykernel_12524\\583147492.py:33: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1284' max='1284' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1284/1284 1:27:12, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>1.648872</td>\n",
       "      <td>0.811512</td>\n",
       "      <td>0.810281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>1.651057</td>\n",
       "      <td>0.806998</td>\n",
       "      <td>0.805413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.041200</td>\n",
       "      <td>1.732562</td>\n",
       "      <td>0.816027</td>\n",
       "      <td>0.815961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1284, training_loss=0.05645516763547888, metrics={'train_runtime': 5238.1631, 'train_samples_per_second': 3.916, 'train_steps_per_second': 0.245, 'total_flos': 493693593917472.0, 'train_loss': 0.05645516763547888, 'epoch': 3.0})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def compute_weighted_loss(outputs, labels, **kwargs):\n",
    "    \"\"\"\n",
    "    outputs: the ModelOutput returned by model(**inputs)\n",
    "    labels:  the groundâ€truth tensor\n",
    "    **kwargs: may include things like num_items_in_batch\n",
    "    \"\"\"\n",
    "    logits = outputs.logits\n",
    "    loss_fct = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    return loss_fct(logits, labels)\n",
    "\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_total_limit=2,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",   \n",
    "    save_safetensors=False   \n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_loss_func=compute_weighted_loss,   \n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c93a4506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions: (3259, 4)\n",
      "Test Accuracy: 0.8450444921755139\n",
      "Test F1 Score: 0.8448877514010509\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_results = trainer.predict(tokenized_datasets[\"test\"])\n",
    "print(f\"Test predictions: {test_results.predictions.shape}\")\n",
    "\n",
    "predicted_labels = np.argmax(test_results.predictions, axis=-1)\n",
    "true_labels = tokenized_datasets[\"test\"][\"labels\"]\n",
    "\n",
    "test_accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "test_f1 = f1_score(true_labels, predicted_labels, average=\"weighted\")\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Test F1 Score: {test_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7506ea08",
   "metadata": {},
   "source": [
    "### **Conlcusion XLM & SuperTweetEval**\n",
    "\n",
    "We began by fine-tuning `xlm-roberta-base` on the TweetEval emotion dataset, achieving:\n",
    "\n",
    "* **Test Accuracy:** 0.8272\n",
    "* **Weighted F1:** 0.8306\n",
    "\n",
    "While the initial results were strong, further analysis revealed a **class imbalance**â€”especially between **Anger** and **Anticipation**â€”which led to consistent misclassification of minority class examples.\n",
    "\n",
    "To address this, we:\n",
    "\n",
    "1. **Analyzed Class Distributions and Errors**\n",
    "\n",
    "   * Noted that Anger dominated the dataset\n",
    "   * Found over 160 Anticipation tweets misclassified as Anger\n",
    "   * Precision and recall for Anticipation were notably lower\n",
    "\n",
    "2. **Introduced a Class-Weighted Loss Function**\n",
    "\n",
    "   * Penalized the model more heavily for errors on underrepresented classes\n",
    "   * Used `CrossEntropyLoss` with manual weights (e.g., `1.5` for Anger, `5.0` for Anticipation)\n",
    "\n",
    "3. **Observed Signs of Overfitting, Yet Improved Test Metrics**\n",
    "\n",
    "   * Training loss dropped sharply, while validation loss increased (suggesting overfitting)\n",
    "   * Despite this, **generalization improved on the test set**\n",
    "\n",
    "On the same test split, this revised pipeline delivered:\n",
    "\n",
    "* **Test Accuracy:** 0.8450\n",
    "* **Weighted F1:** 0.8449\n",
    "\n",
    "Thatâ€™s a **1.78 percentage point gain** in accuracy and **1.43 points** in F1â€”confirming that **class-weighted training mitigated imbalance-driven bias**. Though overfitting was present, we concluded that **the benefits of weighting outweighed the risks**, and the model generalized better, especially on minority emotion classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f89a72",
   "metadata": {},
   "source": [
    "\n",
    "### **Overall Conclusion for XLM-RoBERTa on TweetEval & SuperTweetEval**\n",
    "\n",
    "We evaluated the same `xlm-roberta-base` backbone on two emotion-classification benchmarksâ€”**TweetEval** and **SuperTweetEval**â€”and observed the following:\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. Performance Summary\n",
    "\n",
    "| Dataset            | Test Accuracy | Weighted F1 | Notes on Best Run                                           |\n",
    "| ------------------ | ------------- | ----------- | ----------------------------------------------------------- |\n",
    "| **SuperTweetEval**      | 0.8450        | 0.8449      | After introducing class-weighted loss (5 epochs â†’ 3 epochs) |\n",
    "| **TweetEval** | 0.8086        | 0.7822      | Best at 5 epochs; further tuning (8+ epochs) overfit        |\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. Comparative Analysis\n",
    "\n",
    "* **Higher scores on TweetEval**\n",
    "  SuperTweetEval yielded a **1.78 pp** gain in accuracy and **1.43 pp** gain in F1 over its own unweighted baseline, outperforming TweetEval by **3.64 pp** in accuracy and **6.27 pp** in F1.\n",
    "* **Class Distribution & Difficulty**\n",
    "  TweetEval appears to have **more nuanced or noisier labels**, amplifying overfitting after extended training. In contrast, TweetEvalâ€™s clearer class definitionsâ€”and the corrective effect of class weightingâ€”allowed the model to learn robust decision boundaries.\n",
    "* **Impact of Overfitting**\n",
    "  On TweetEval, validation loss rose sharply after 5 epochs, driving test metrics down by nearly **4.1 pp** in accuracy when training for 8 epochs. SuperTweetEval, however, benefited from the weighted loss despite some overfitting signs, because the weighting better aligned with its class imbalance.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. Why XLM Performed Best on SuperTweetEval\n",
    "\n",
    "1. **Balanced Improvement via Class Weighting**\n",
    "   SuperTweetEvalâ€™s two-class imbalance (Anger vs Anticipation) was directly mitigated by weighted cross-entropy, boosting minority-class recall without catastrophically overfitting.\n",
    "2. **Simpler Label Space**\n",
    "   SuperTweetEvalâ€™s binary setup (vs. SuperTweetEvalâ€™s multi-class or more granular splits) allowed XLM-RoBERTa to learn discriminative patterns more cleanly.\n",
    "3. **Data Quality & Size**\n",
    "   Although both datasets are tweet-based, SuperTweetEvalâ€™s emotion subset is smaller but cleaner, whereas SuperTweetEvalâ€™s expanded annotations introduce label noise that the model struggles to generalize over.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. Final Takeaway & Next Steps\n",
    "\n",
    "* **Deploy the SuperTweetEval model** (accuracy 0.845, F1 0.845) for immediate applications, as it demonstrates the strongest generalization.\n",
    "* **For TweetEval**, explore noise-robust techniques:\n",
    "\n",
    "  * **Label smoothing** or **confidence-based filtering**\n",
    "  * **Data augmentation** (back-translation, paraphrasing)\n",
    "  * **Curriculum learning** starting from cleanest subsets\n",
    "\n",
    "By tailoring loss functions and leveraging dataset-specific insights, XLM-RoBERTa can be steered toward its best performance on each taskâ€”excelling on SuperTweetEval today, with clear paths to boost TweetEval tomorrow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dbecca",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CS345Project-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
